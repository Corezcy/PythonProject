#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘éŸ³è½¨æå–ä¸å­—å¹•ç”Ÿæˆå·¥å…· (è·¨å¹³å°åŠ é€Ÿç‰ˆ)
æ”¯æŒ: macOS (Metal), Linux (CUDA), Windows (CPU)
éœ€è¦å®‰è£…: pip install faster-whisper ffmpeg-python opencc
ç³»ç»Ÿéœ€è¦å®‰è£… FFmpeg
"""

import os
import sys
import platform
from faster_whisper import WhisperModel
import ffmpeg
from datetime import timedelta
from tqdm import tqdm
import time
from opencc import OpenCC

cc_converter = OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“è½¬æ¢å™¨


def detect_device():
    """
    è‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¡ç®—è®¾å¤‡
    
    Returns:
        tuple: (device, compute_type, description)
    """
    system = platform.system()
    
    # å°è¯•æ£€æµ‹ CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            return "cuda", "float16", f"NVIDIA GPU: {gpu_name}"
    except ImportError:
        pass
    
    # macOS ä½¿ç”¨ CPU (è‡ªåŠ¨åˆ©ç”¨ Metal)
    if system == "Darwin":
        return "cpu", "int8", "macOS CPU (Metal åŠ é€Ÿ)"
    
    # Linux/Windows æ²¡æœ‰ CUDA åˆ™ä½¿ç”¨ CPU
    return "cpu", "int8", f"{system} CPU"


def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)"""
    td = timedelta(seconds=seconds)
    hours = td.seconds // 3600
    minutes = (td.seconds % 3600) // 60
    secs = td.seconds % 60
    millis = td.microseconds // 1000
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def get_video_duration(video_path):
    """
    è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    
    Returns:
        float: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    """
    try:
        probe = ffmpeg.probe(video_path)
        duration = float(probe['format']['duration'])
        return duration
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•è·å–è§†é¢‘æ—¶é•¿: {e}")
        return None


def extract_audio(video_path, audio_path):
    """
    ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³è½¨
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        audio_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    print(f"æ­£åœ¨ä» {video_path} æå–éŸ³è½¨...")
    
    try:
        # ä½¿ç”¨ ffmpeg-python æå–éŸ³é¢‘
        stream = ffmpeg.input(video_path)
        stream = ffmpeg.output(stream, audio_path, 
                              acodec='pcm_s16le',  # WAV æ ¼å¼
                              ac=1,                 # å•å£°é“
                              ar='16000')           # é‡‡æ ·ç‡ 16kHz
        ffmpeg.run(stream, overwrite_output=True, capture_stdout=True, capture_stderr=True)
        print(f"âœ“ éŸ³è½¨æå–å®Œæˆ: {audio_path}")
        return True
    except ffmpeg.Error as e:
        print(f"âœ— æå–éŸ³è½¨å¤±è´¥: {e.stderr.decode()}")
        return False


def transcribe_audio_fast(audio_path, model_size="medium", language="zh", device="auto", duration=None):
    """
    ä½¿ç”¨ faster-whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«
    è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡ (CUDA/Metal/CPU)
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large-v2, large-v3)
        language: è¯­è¨€ä»£ç  (zh=ä¸­æ–‡, en=è‹±æ–‡, auto=è‡ªåŠ¨æ£€æµ‹)
        device: è®¡ç®—è®¾å¤‡ (auto, cpu, cuda)
        duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦
    
    Returns:
        è½¬å½•ç»“æœåˆ—è¡¨
    """
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
    if device == "auto":
        device, compute_type, device_desc = detect_device()
        print(f"\næ£€æµ‹åˆ°è®¡ç®—è®¾å¤‡: {device_desc}")
    else:
        # æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡
        if device == "cuda":
            compute_type = "float16"
            device_desc = "NVIDIA CUDA GPU"
        else:
            compute_type = "int8"
            device_desc = "CPU"
        print(f"\nä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device_desc}")
    
    print(f"æ­£åœ¨åŠ è½½ faster-whisper {model_size} æ¨¡å‹...")
    print(f"è®¡ç®—ç²¾åº¦: {compute_type}")
    
    # æ ¹æ®è®¾å¤‡é…ç½®å‚æ•°
    model_kwargs = {
        "model_size_or_path": model_size,
        "device": device,
        "compute_type": compute_type
    }
    
    # CPU æ¨¡å¼ä¸‹è®¾ç½®çº¿ç¨‹æ•°
    if device == "cpu":
        model_kwargs["cpu_threads"] = os.cpu_count() or 4
    
    model = WhisperModel(**model_kwargs)
    
    print(f"æ­£åœ¨è¯†åˆ«è¯­éŸ³ (è¯­è¨€: {language})...")
    if duration:
        print(f"éŸ³é¢‘æ—¶é•¿: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
    
    # é…ç½®è½¬å½•å‚æ•°
    transcribe_kwargs = {
        "audio": audio_path,
        "beam_size": 5,
        "vad_filter": True,
        "vad_parameters": dict(min_silence_duration_ms=500)
    }
    
    # æ‰§è¡Œè½¬å½•
    start_time = time.time()
    
    if language.lower() == "auto":
        segments, info = model.transcribe(**transcribe_kwargs)
        detected_language = info.language
        print(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language} (ç½®ä¿¡åº¦: {info.language_probability:.2%})")
    else:
        transcribe_kwargs["language"] = language
        segments, info = model.transcribe(**transcribe_kwargs)
    
    # ä½¿ç”¨è¿›åº¦æ¡æ”¶é›†ç‰‡æ®µ
    segments_list = []
    
    if duration:
        # æœ‰æ—¶é•¿ä¿¡æ¯ï¼Œæ˜¾ç¤ºç™¾åˆ†æ¯”è¿›åº¦
        with tqdm(total=100, desc="è¯†åˆ«è¿›åº¦", unit="%", ncols=80, 
                  bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:
            last_progress = 0
            for segment in segments:
                segments_list.append(segment)
                # æ ¹æ®æ—¶é—´è®¡ç®—è¿›åº¦
                current_progress = int((segment.end / duration) * 100)
                if current_progress > last_progress:
                    pbar.update(current_progress - last_progress)
                    last_progress = current_progress
                    # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ—¶é—´ç‚¹
                    pbar.set_postfix_str(f"æ—¶é—´: {segment.end:.1f}s / {duration:.1f}s")
            # ç¡®ä¿è¿›åº¦æ¡åˆ°è¾¾ 100%
            pbar.update(100 - last_progress)
    else:
        # æ²¡æœ‰æ—¶é•¿ä¿¡æ¯ï¼Œåªæ˜¾ç¤ºç‰‡æ®µè®¡æ•°
        print("\nå¼€å§‹è¯†åˆ«...")
        with tqdm(desc="å¤„ç†ç‰‡æ®µ", unit="æ®µ", ncols=80) as pbar:
            for segment in segments:
                segments_list.append(segment)
                pbar.update(1)
                pbar.set_postfix_str(f"å½“å‰æ—¶é—´: {segment.end:.1f}s")
    
    elapsed_time = time.time() - start_time
    
    print(f"\nâœ“ è¯­éŸ³è¯†åˆ«å®Œæˆ (å…± {len(segments_list)} ä¸ªç‰‡æ®µ)")
    print(f"è¯†åˆ«è€—æ—¶: {elapsed_time:.1f} ç§’")
    
    # è®¡ç®—è¯†åˆ«é€Ÿåº¦
    if duration and duration > 0:
        speed_ratio = duration / elapsed_time
        print(f"å¤„ç†é€Ÿåº¦: {speed_ratio:.2f}x å®æ—¶é€Ÿåº¦")
        if device == "cuda":
            print(f"GPU åŠ é€Ÿæ•ˆæœæ˜¾è‘— ğŸš€")
    
    return segments_list


def save_srt(segments, srt_path):
    """
    å°†è¯†åˆ«ç»“æœä¿å­˜ä¸º SRT å­—å¹•æ–‡ä»¶ï¼Œè‡ªåŠ¨å°†ç¹ä½“è½¬æ¢ä¸ºç®€ä½“
    
    Args:
        segments: faster-whisper è¯†åˆ«çš„ç‰‡æ®µåˆ—è¡¨
        srt_path: è¾“å‡º SRT æ–‡ä»¶è·¯å¾„
    """
    print(f"\næ­£åœ¨ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶...")
    
    with open(srt_path, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(segments, 1):
            # å­—å¹•åºå·
            f.write(f"{i}\n")
            
            # æ—¶é—´è½´
            start_time = format_timestamp(segment.start)
            end_time = format_timestamp(segment.end)
            f.write(f"{start_time} --> {end_time}\n")
            
            # å­—å¹•å†…å®¹ï¼Œè½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
            simplified_text = cc_converter.convert(segment.text.strip())
            f.write(f"{simplified_text}\n\n")
    
    print(f"âœ“ SRT å­—å¹•å·²ä¿å­˜: {srt_path}")


def save_txt(segments, txt_path):
    """
    å°†è¯†åˆ«ç»“æœä¿å­˜ä¸ºçº¯æ–‡æœ¬æ–‡ä»¶
    
    Args:
        segments: faster-whisper è¯†åˆ«çš„ç‰‡æ®µåˆ—è¡¨
        txt_path: è¾“å‡º TXT æ–‡ä»¶è·¯å¾„
    """
    print(f"æ­£åœ¨ç”Ÿæˆæ–‡æœ¬æ–‡ä»¶...")
    
    with open(txt_path, 'w', encoding='utf-8') as f:
        for segment in segments:
            f.write(segment.text.strip() + "\n")
    
    print(f"âœ“ æ–‡æœ¬å·²ä¿å­˜: {txt_path}")


def print_system_info():
    """æ‰“å°ç³»ç»Ÿå’Œç¯å¢ƒä¿¡æ¯"""
    print("\nç³»ç»Ÿä¿¡æ¯:")
    print(f"  æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"  Python: {sys.version.split()[0]}")
    print(f"  CPU æ ¸å¿ƒæ•°: {os.cpu_count()}")
    
    try:
        import torch
        print(f"  PyTorch: {torch.__version__}")
        if torch.cuda.is_available():
            print(f"  CUDA: {torch.version.cuda}")
            print(f"  GPU: {torch.cuda.get_device_name(0)}")
            print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print(f"  CUDA: ä¸å¯ç”¨")
    except ImportError:
        print(f"  PyTorch: æœªå®‰è£…")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    if len(sys.argv) < 2:
        print("=" * 70)
        print("è§†é¢‘å­—å¹•ç”Ÿæˆå·¥å…· (è·¨å¹³å°åŠ é€Ÿç‰ˆ)")
        print("=" * 70)
        print("\nç”¨æ³•: python script.py <è§†é¢‘æ–‡ä»¶è·¯å¾„> [æ¨¡å‹å¤§å°] [è¯­è¨€] [è®¾å¤‡]")
        print("\nç¤ºä¾‹:")
        print("  python script.py video.mp4                    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡")
        print("  python script.py video.mp4 medium zh          # æŒ‡å®šæ¨¡å‹å’Œè¯­è¨€")
        print("  python script.py video.mp4 medium zh cuda     # å¼ºåˆ¶ä½¿ç”¨ CUDA")
        print("  python script.py video.mp4 small en cpu       # å¼ºåˆ¶ä½¿ç”¨ CPU")
        print("\nå‚æ•°è¯´æ˜:")
        print("  æ¨¡å‹å¤§å°: tiny, base, small, medium, large-v2, large-v3")
        print("    - tiny/base: æå¿«ï¼Œé€‚åˆå®æ—¶å­—å¹• (GPU: <1ç§’/åˆ†é’Ÿ)")
        print("    - small: å¿«é€Ÿä¸”å‡†ç¡®åº¦ä¸é”™ (GPU: ~2ç§’/åˆ†é’Ÿ)")
        print("    - medium: æ¨èï¼Œå‡†ç¡®åº¦é«˜ (GPU: ~5ç§’/åˆ†é’Ÿ, CPU: ~2.5åˆ†é’Ÿ/åˆ†é’Ÿ)")
        print("    - large-v3: æœ€é«˜å‡†ç¡®åº¦ (GPU: ~10ç§’/åˆ†é’Ÿ, CPU: ~6åˆ†é’Ÿ/åˆ†é’Ÿ)")
        print("\n  è¯­è¨€: zh(ä¸­æ–‡), en(è‹±æ–‡), ja(æ—¥è¯­), auto(è‡ªåŠ¨æ£€æµ‹)")
        print("\n  è®¾å¤‡: auto(è‡ªåŠ¨), cuda(GPU), cpu")
        print("\nå¹³å°ä¼˜åŒ–:")
        print("  âœ“ Linux + CUDA: è‡ªåŠ¨ä½¿ç”¨ float16 ç²¾åº¦ï¼Œé€Ÿåº¦æœ€å¿«")
        print("  âœ“ macOS: è‡ªåŠ¨ä½¿ç”¨ Metal åŠ é€Ÿ")
        print("  âœ“ Windows/Linux(æ— GPU): ä½¿ç”¨ int8 é‡åŒ–åŠ é€Ÿ")
        
        print_system_info()
        sys.exit(1)
    
    video_path = sys.argv[1]
    model_size = sys.argv[2] if len(sys.argv) > 2 else "medium"
    language = sys.argv[3] if len(sys.argv) > 3 else "zh"
    device = sys.argv[4] if len(sys.argv) > 4 else "auto"
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {video_path}")
        sys.exit(1)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    base_name = os.path.splitext(video_path)[0]
    audio_path = f"{base_name}_audio.wav"
    srt_path = f"{base_name}.srt"
    txt_path = f"{base_name}_transcript.txt"
    
    print("=" * 70)
    print("è§†é¢‘å­—å¹•ç”Ÿæˆå·¥å…· (è·¨å¹³å°åŠ é€Ÿç‰ˆ)")
    print("=" * 70)
    print(f"è¾“å…¥è§†é¢‘: {video_path}")
    print(f"æ¨¡å‹å¤§å°: {model_size}")
    print(f"è¯†åˆ«è¯­è¨€: {language}")
    print(f"è®¡ç®—è®¾å¤‡: {device}")
    print("=" * 70)
    
    # è·å–è§†é¢‘æ—¶é•¿
    duration = get_video_duration(video_path)
    if duration:
        print(f"è§†é¢‘æ—¶é•¿: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
    
    # æ­¥éª¤ 1: æå–éŸ³è½¨
    if not extract_audio(video_path, audio_path):
        sys.exit(1)
    
    # æ­¥éª¤ 2: è¯­éŸ³è¯†åˆ«
    try:
        segments = transcribe_audio_fast(audio_path, model_size, language, device, duration)
    except Exception as e:
        print(f"\nâœ— è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        print("\næ•…éšœæ’é™¤:")
        print("1. ç¡®ä¿å·²å®‰è£…: pip install faster-whisper ffmpeg-python tqdm")
        print("2. ç¡®ä¿å·²å®‰è£… FFmpeg")
        print("   - macOS: brew install ffmpeg")
        print("   - Linux: sudo apt install ffmpeg")
        print("   - Windows: ä» https://ffmpeg.org ä¸‹è½½")
        print("3. CUDA ç”¨æˆ·éœ€è¦å®‰è£…: pip install torch --index-url https://download.pytorch.org/whl/cu118")
        sys.exit(1)
    
    # æ­¥éª¤ 3: ä¿å­˜å­—å¹•æ–‡ä»¶
    save_srt(segments, srt_path)
    save_txt(segments, txt_path)
    
    # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    cleanup = input("\næ˜¯å¦åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶? (y/n): ")
    if cleanup.lower() == 'y':
        os.remove(audio_path)
        print(f"âœ“ å·²åˆ é™¤: {audio_path}")
    
    print("\n" + "=" * 70)
    print("âœ“ å…¨éƒ¨å®Œæˆ!")
    print("=" * 70)
    print(f"å­—å¹•æ–‡ä»¶: {srt_path}")
    print(f"æ–‡æœ¬æ–‡ä»¶: {txt_path}")


if __name__ == "__main__":
    main()
